{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46ba1a7e",
   "metadata": {},
   "source": [
    "# 1. Train and evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4fa641",
   "metadata": {},
   "source": [
    "We're gonna use 3 type of Machine Learning (for the classification problem with multiple results) and use the one that has the best performance. They are:\n",
    "- **Random Forest**\n",
    "- **XGBoost**\n",
    "- **CatBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b42018",
   "metadata": {},
   "source": [
    "## 1.1 Import neccessary packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a6d13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training shape: (203820, 36)\n",
      "Balanced Training shape: (445239, 36)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import duckdb\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Model and pre-processing imports\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Metric imports\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- Data Loading (from your original notebook) ---\n",
    "\n",
    "# Load TRAIN\n",
    "con = duckdb.connect(\"../database/ML/X_train.duckdb\")\n",
    "X_train = con.execute(\"SELECT * FROM X_train\").df()\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect(\"../database/ML/y_train.duckdb\")\n",
    "y_train = con.execute(\"SELECT * FROM y_train\").df()\n",
    "con.close()\n",
    "\n",
    "# Load TEST\n",
    "con = duckdb.connect(\"../database/ML/X_test.duckdb\")\n",
    "X_test = con.execute(\"SELECT * FROM X_test\").df()\n",
    "con.close()\n",
    "\n",
    "con = duckdb.connect(\"../database/ML/y_test.duckdb\")\n",
    "y_test = con.execute(\"SELECT * FROM y_test\").df()\n",
    "con.close()\n",
    "\n",
    "# Apply ADASYN to balance the training data\n",
    "adasyn = ADASYN(random_state=42, n_neighbors=6)\n",
    "X_train_balanced, y_train_balanced = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Original Training shape: {X_train.shape}\")\n",
    "print(f\"Balanced Training shape: {X_train_balanced.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7990f47d",
   "metadata": {},
   "source": [
    "## 1.2 Define model and run comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7410214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train_balanced, y_train_balanced, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Trains a model on balanced data and evaluates it on the test set.\n",
    "    Returns a dictionary of key metrics and the trained model.\n",
    "    \"\"\"\n",
    "    print(f\"--- Training {model_name} ---\")\n",
    "\n",
    "    # Fit the model\n",
    "    if model_name == \"CatBoost\":\n",
    "        # CatBoost has its own fitting method and prints verbose output\n",
    "        model.fit(X_train_balanced, y_train_balanced)\n",
    "    else:\n",
    "        # Standard fit for scikit-learn compatible models\n",
    "        # .values.ravel() is needed to convert the DataFrame column to the expected shape\n",
    "        model.fit(X_train_balanced, y_train_balanced.values.ravel())\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics (zero_division=0 handles cases where a class has no true or predicted samples)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # Store results\n",
    "    metrics = {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Confusion Matrix\": confusion_matrix(y_test, y_pred),\n",
    "        \"Trained Model\": model,\n",
    "    }\n",
    "\n",
    "    print(f\"--- Finished {model_name}. Accuracy: {accuracy:.4f} ---\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3439f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training CatBoost ---\n",
      "0:\tlearn: 1.0969137\ttotal: 118ms\tremaining: 2m 20s\n",
      "100:\tlearn: 0.9852967\ttotal: 5.63s\tremaining: 1m 1s\n",
      "200:\tlearn: 0.9368638\ttotal: 11s\tremaining: 54.5s\n",
      "300:\tlearn: 0.9118837\ttotal: 16.1s\tremaining: 48.1s\n",
      "400:\tlearn: 0.8974849\ttotal: 21.1s\tremaining: 42.1s\n",
      "500:\tlearn: 0.8879095\ttotal: 26.4s\tremaining: 36.9s\n",
      "600:\tlearn: 0.8808380\ttotal: 31.5s\tremaining: 31.3s\n",
      "700:\tlearn: 0.8751713\ttotal: 36.7s\tremaining: 26.1s\n",
      "800:\tlearn: 0.8702011\ttotal: 42.2s\tremaining: 21s\n",
      "900:\tlearn: 0.8657788\ttotal: 47.1s\tremaining: 15.6s\n",
      "1000:\tlearn: 0.8618907\ttotal: 52s\tremaining: 10.3s\n",
      "1100:\tlearn: 0.8584528\ttotal: 56.9s\tremaining: 5.12s\n",
      "1199:\tlearn: 0.8549856\ttotal: 1m 2s\tremaining: 0us\n",
      "--- Finished CatBoost. Accuracy: 0.4890 ---\n",
      "--- Training RandomForest ---\n",
      "--- Finished RandomForest. Accuracy: 0.5456 ---\n",
      "--- Training XGBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoan/VSCode/projects/local_elt_pipeline/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [03:50:09] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished XGBoost. Accuracy: 0.5514 ---\n"
     ]
    }
   ],
   "source": [
    "# Define the models to compare\n",
    "\n",
    "# 1. CatBoost\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=1200,\n",
    "    learning_rate=0.005,\n",
    "    depth=6,\n",
    "    loss_function=\"MultiClass\",\n",
    "    verbose=100,\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "# 2. Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300, max_depth=22, random_state=42, n_jobs=-1, class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "# 3. XGBoost Classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"mlogloss\",\n",
    ")\n",
    "\n",
    "models_to_compare = [\n",
    "    (catboost_model, \"CatBoost\"),\n",
    "    (rf_model, \"RandomForest\"),\n",
    "    (xgb_model, \"XGBoost\"),\n",
    "]\n",
    "\n",
    "# Run the comparison loop\n",
    "comparison_results = []\n",
    "for model, name in models_to_compare:\n",
    "    results = train_and_evaluate_model(\n",
    "        model, X_train_balanced, y_train_balanced, X_test, y_test, name\n",
    "    )\n",
    "    comparison_results.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f003144",
   "metadata": {},
   "source": [
    "## 1.3 Display Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6ebb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Model Comparison Summary\n",
      "          Model Accuracy Precision  Recall F1 Score\n",
      "0      CatBoost   0.4890    0.7303  0.4890   0.5199\n",
      "1  RandomForest   0.5456    0.7153  0.5456   0.5807\n",
      "2       XGBoost   0.5514    0.7236  0.5514   0.5849\n",
      "\n",
      "---\n",
      "## Confusion Matrices\n",
      "\n",
      "--- CatBoost Confusion Matrix ---\n",
      "\n",
      "[[26440 19822 18457]\n",
      " [ 1588  7869   482]\n",
      " [ 1837  2447  8410]]\n",
      "\n",
      "--- RandomForest Confusion Matrix ---\n",
      "\n",
      "[[32977 17009 14733]\n",
      " [ 2253  7058   628]\n",
      " [ 3172  1901  7621]]\n",
      "\n",
      "--- XGBoost Confusion Matrix ---\n",
      "\n",
      "[[32881 15704 16134]\n",
      " [ 2280  7215   444]\n",
      " [ 2728  1894  8072]]\n"
     ]
    }
   ],
   "source": [
    "# Compile the results into a DataFrame\n",
    "metrics_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "# Drop the Confusion Matrix and Trained Model for the summary table\n",
    "summary_df = metrics_df.drop(columns=[\"Confusion Matrix\", \"Trained Model\"])\n",
    "\n",
    "# Format for display\n",
    "summary_df[\"Accuracy\"] = summary_df[\"Accuracy\"].map(\"{:.4f}\".format)\n",
    "summary_df[\"Precision\"] = summary_df[\"Precision\"].map(\"{:.4f}\".format)\n",
    "summary_df[\"Recall\"] = summary_df[\"Recall\"].map(\"{:.4f}\".format)\n",
    "summary_df[\"F1 Score\"] = summary_df[\"F1 Score\"].map(\"{:.4f}\".format)\n",
    "\n",
    "print(\"## Model Comparison Summary\")\n",
    "print(summary_df)\n",
    "\n",
    "print(\"\\n---\")\n",
    "print(\"## Confusion Matrices\")\n",
    "\n",
    "# Print each confusion matrix for detailed analysis\n",
    "for index, row in metrics_df.iterrows():\n",
    "    print(f\"\\n--- {row['Model']} Confusion Matrix ---\\n\")\n",
    "    print(row[\"Confusion Matrix\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7cee6",
   "metadata": {},
   "source": [
    "# 2. Save the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b1b6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed model saved to ../src/models/xgboost.pkl\n"
     ]
    }
   ],
   "source": [
    "save_path = \"../src/models/xgboost.pkl\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# compress=3 is a good balance between speed and size (range 0-9)\n",
    "joblib.dump(xgb_model, save_path, compress=3)\n",
    "\n",
    "print(f\"Compressed model saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ELT Local)",
   "language": "python",
   "name": "elt-local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
